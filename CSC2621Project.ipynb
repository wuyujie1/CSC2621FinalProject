{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKQqZL6ousGh",
        "outputId": "133b5435-a85f-4d93-e0ed-bc656f06e1dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFcfeFXovLhK"
      },
      "outputs": [],
      "source": [
        "# Necessary packages\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn\n",
        "import torch.optim\n",
        "import torch.nn.functional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb2ixrABI_Oc"
      },
      "outputs": [],
      "source": [
        "# Global Vars\n",
        "\n",
        "device = 'cuda:0'\n",
        "\n",
        "desired_height = 512\n",
        "desired_width = 256\n",
        "\n",
        "b_size = 8\n",
        "num_batches = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYtPtyCjwML3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ae5fe5-c158-4846-fea4-3e5ad7aba5a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training set preprocessing complete !\n",
            "test set preprocessing complete !\n"
          ]
        }
      ],
      "source": [
        "# Preprocess data, generate slope file\n",
        "def all_angles(img_dir, filenames_csv, landmarks_csv, out_dir):\n",
        "    \n",
        "    all_landmarks = pd.read_csv(landmarks_csv, header=None)\n",
        "    filenames = pd.read_csv(filenames_csv, header=None)\n",
        "    \n",
        "    angles = []    \n",
        "    for i, name in enumerate(filenames.iloc[:,0]):\n",
        "        img = cv2.imread(img_dir + name)\n",
        "        w = img.shape[0]\n",
        "        h = img.shape[1]\n",
        "\n",
        "        curr_landmark = all_landmarks.loc[i].values\n",
        "        curr_slopes = []\n",
        "        for m in range (0,68,4):\n",
        "            slope_upper = (round(w * curr_landmark[m + 1 + 68]) - round(w * curr_landmark[m + 68])) / (\n",
        "                     round(h * curr_landmark[m + 1]) - round(h * curr_landmark[m]) + 1e-7)\n",
        "            slope_lower = (round(w * curr_landmark[m + 3 + 68]) - round(w * curr_landmark[m + 2 + 68])) / (\n",
        "                    round(h * curr_landmark[m + 3]) - round(h * curr_landmark[m + 2]) + 1e-7)\n",
        "            curr_slopes.append((slope_upper + slope_lower) / 2)\n",
        "            \n",
        "        curr_angles = []\n",
        "        # 8 angles\n",
        "        for i in range(1, 9):\n",
        "          curr_angles.append(abs(np.rad2deg(np.arctan((\n",
        "        curr_slopes[0] - curr_slopes[i]) / (1+curr_slopes[0] * curr_slopes[i])))) / 180)\n",
        "        # 7 angles\n",
        "        for i in range(9, 16):\n",
        "          curr_angles.append(abs(np.rad2deg(np.arctan((\n",
        "        curr_slopes[i] - curr_slopes[16]) / (1+curr_slopes[i] * curr_slopes[16])))) / 180)\n",
        "        # 118 angles\n",
        "        for i in range(1, 16):\n",
        "          for j in range(i + 1, 16):\n",
        "            curr_angles.append(abs(np.rad2deg(np.arctan((\n",
        "        curr_slopes[i] - curr_slopes[j]) / (1+curr_slopes[i] * curr_slopes[j])))) / 180)\n",
        "        angles.append(curr_angles)\n",
        "\n",
        "    np.savetxt(out_dir, angles, delimiter =\", \", fmt ='% s')\n",
        "\n",
        "# train\n",
        "all_angles('./drive/MyDrive/boostnet_labeldata/data/training/','./drive/MyDrive/boostnet_labeldata/labels/training/filenames.csv','./drive/MyDrive/boostnet_labeldata/labels/training/landmarks.csv', \"./drive/MyDrive/boostnet_labeldata/training_set_all_angles.csv\")\n",
        "print(\"training set preprocessing complete !\")\n",
        "\n",
        "# test\n",
        "all_angles('./drive/MyDrive/boostnet_labeldata/data/test/','./drive/MyDrive/boostnet_labeldata/full_test_filenames.csv','./drive/MyDrive/boostnet_labeldata/full_test_landmarks.csv', \"./drive/MyDrive/boostnet_labeldata/test_set_all_angles.csv\")\n",
        "print(\"test set preprocessing complete !\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JamNJD5j3y4t",
        "outputId": "ba57e6be-93b3-4e6c-ece7-7ec43a32472a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training data loaded !\n",
            "test data loaded !\n"
          ]
        }
      ],
      "source": [
        "# Load train, test data\n",
        "\n",
        "# train dir\n",
        "train_img = \"./drive/MyDrive/boostnet_labeldata/data/training/\"\n",
        "train_filenames = csv.reader(open(\"./drive/MyDrive/boostnet_labeldata/labels/training/filenames.csv\", 'r'))\n",
        "train_landmarks = csv.reader(open(\"./drive/MyDrive/boostnet_labeldata/training_set_all_angles.csv\", 'r'))\n",
        "\n",
        "# test dir\n",
        "test_img = \"./drive/MyDrive/boostnet_labeldata/data/test/\"\n",
        "test_filenames = csv.reader(open(\"./drive/MyDrive/boostnet_labeldata/full_test_filenames.csv\", 'r'))\n",
        "test_landmarks = csv.reader(open(\"./drive/MyDrive/boostnet_labeldata/test_set_all_angles.csv\", 'r'))\n",
        "\n",
        "class creatDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, img_dir, filenames_dir, landmarks_dir, is_train):\n",
        "        self.img_dir = img_dir\n",
        "        self.filenames = filenames_dir\n",
        "        self.landmarks = landmarks_dir\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        \n",
        "        for landmark in self.landmarks:\n",
        "            coordinate_list = []\n",
        "            for coordinate in landmark:\n",
        "                coordinate_list.append(float(coordinate))\n",
        "            self.labels.append(torch.Tensor(coordinate_list))\n",
        "\n",
        "        for i, filename in enumerate(self.filenames):\n",
        "            image = cv2.imread(self.img_dir + filename[0], cv2.IMREAD_GRAYSCALE)\n",
        "            image = cv2.resize(image, (desired_width, desired_height))\n",
        "            \n",
        "            image = np.reshape(image, (1, image.shape[0], image.shape[1]))\n",
        "            image_tensor = torch.from_numpy(image).float()\n",
        "            \n",
        "            self.images.append(image_tensor)\n",
        "\n",
        "        if is_train:\n",
        "          self.images = self.images[:-1]\n",
        "          self.labels = self.labels[:-1]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.images[index]\n",
        "        label = self.labels[index]\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "# train\n",
        "training = creatDataset(train_img, train_filenames, train_landmarks, True)\n",
        "train_loader = torch.utils.data.DataLoader(training, batch_size=b_size, shuffle=True, num_workers=2)\n",
        "print(\"training data loaded !\")\n",
        "\n",
        "# test\n",
        "test = creatDataset(test_img, test_filenames, test_landmarks, False)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=b_size, shuffle=True, num_workers=2)\n",
        "print(\"test data loaded !\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K98arpV38Ez2"
      },
      "outputs": [],
      "source": [
        "# Loss function\n",
        "\n",
        "#loss_fcn = torch.nn.CrossEntropyLoss().to(device)\n",
        "loss_fcn = torch.nn.MSELoss().to(device)\n",
        "\n",
        "def compute_loss(net, data_loader):\n",
        "    s = 0\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(data_loader, 0):\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            prediction = net(images)\n",
        "            loss = loss_fcn(prediction.float(), labels.float())\n",
        "            s += loss.item()\n",
        "            \n",
        "    return s / len(data_loader)\n",
        "\n",
        "# Network\n",
        "\n",
        "class Network(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        self.pool_layer = torch.nn.MaxPool2d(2, 2)\n",
        "        self.con_layer_1 = torch.nn.Conv2d(1, 2, 3, 1, 1)\n",
        "        self.con_layer_2 = torch.nn.Conv2d(2, 4, 3, 1, 1)\n",
        "        self.con_layer_3 = torch.nn.Conv2d(4, 8, 3, 1, 1)\n",
        "        self.con_layer_4 = torch.nn.Conv2d(8, 16, 3, 1, 1)\n",
        "        self.con_layer_5 = torch.nn.Conv2d(16, 16, 3, 1, 1)\n",
        "        self.fully_connected_1 = torch.nn.Linear(16 * 16 * 8, 512)\n",
        "        self.fully_connected_2 = torch.nn.Linear(512, 120)\n",
        "        \n",
        "    def forward(self, x):        \n",
        "        x = torch.nn.functional.relu(self.con_layer_1(x))\n",
        "        x = self.pool_layer(x)\n",
        "        x = torch.nn.functional.relu(self.con_layer_2(x))\n",
        "        x = self.pool_layer(x)\n",
        "        x = torch.nn.functional.relu(self.con_layer_3(x))\n",
        "        x = self.pool_layer(x)\n",
        "        x = torch.nn.functional.relu(self.con_layer_4(x))\n",
        "        x = self.pool_layer(x)\n",
        "        x = torch.nn.functional.relu(self.con_layer_5(x))\n",
        "        x = self.pool_layer(x)\n",
        "        x = x.view(-1, 16 * 16 * 8)\n",
        "        x = torch.nn.functional.relu(self.fully_connected_1(x))\n",
        "        x = self.fully_connected_2(x)\n",
        "        return x\n",
        "\n",
        "net = Network().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycSP098X-_ky",
        "outputId": "a3b2f18a-72f1-41d7-8ac0-01a8ffc4a382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1 train_loss 0.004214394182781689 test_loss 0.003726842758624116\n",
            "Iteration: 2 train_loss 0.003422327912024533 test_loss 0.003221741582819959\n",
            "Iteration: 3 train_loss 0.0036005240040443216 test_loss 0.0035952509060734883\n",
            "Iteration: 4 train_loss 0.002492892546191191 test_loss 0.0029198918491601944\n",
            "Iteration: 5 train_loss 0.0026707007525449927 test_loss 0.0033455698248872068\n",
            "Iteration: 6 train_loss 0.001940727940624735 test_loss 0.0029912393947597593\n",
            "Iteration: 7 train_loss 0.001725759500307807 test_loss 0.0026671239429560956\n",
            "Iteration: 8 train_loss 0.0015066971541576398 test_loss 0.002607074664410902\n",
            "Iteration: 9 train_loss 0.0013739122567737164 test_loss 0.0027358766819816083\n",
            "Iteration: 10 train_loss 0.0014006582355553594 test_loss 0.0027826081204693764\n",
            "Iteration: 11 train_loss 0.001321930766183262 test_loss 0.0027567813303903677\n",
            "Iteration: 12 train_loss 0.0013903203992716346 test_loss 0.002937498895335011\n",
            "Iteration: 13 train_loss 0.001367527785381147 test_loss 0.003140312030154746\n",
            "Iteration: 14 train_loss 0.0009918400617607403 test_loss 0.002851558783731889\n",
            "Iteration: 15 train_loss 0.0009709601775587847 test_loss 0.0027364483903511427\n",
            "Iteration: 16 train_loss 0.0011714338511713625 test_loss 0.003020619053131668\n",
            "Iteration: 17 train_loss 0.0010211004987165022 test_loss 0.0027938222483498976\n",
            "Iteration: 18 train_loss 0.0009686275800049771 test_loss 0.0028105929486628156\n",
            "Iteration: 19 train_loss 0.0008318790081830229 test_loss 0.0027429444853623863\n",
            "Iteration: 20 train_loss 0.0009012370285442254 test_loss 0.002935862044978421\n",
            "Iteration: 21 train_loss 0.0007824094177825221 test_loss 0.002733651932430803\n",
            "Iteration: 22 train_loss 0.0007650691800032898 test_loss 0.0027477589719637763\n",
            "Iteration: 23 train_loss 0.000717689431864225 test_loss 0.0027541345534700667\n",
            "Iteration: 24 train_loss 0.0007356906115698318 test_loss 0.0028539897648443002\n",
            "Iteration: 25 train_loss 0.0007497073073560993 test_loss 0.0028117444235249422\n",
            "Iteration: 26 train_loss 0.0006711786865101506 test_loss 0.0026997821951226797\n",
            "Iteration: 27 train_loss 0.0008443952040882626 test_loss 0.0029526199814426946\n",
            "Iteration: 28 train_loss 0.0007003614055671885 test_loss 0.0028666569269262254\n",
            "Iteration: 29 train_loss 0.0007542998690041713 test_loss 0.0029447751221596263\n",
            "Iteration: 30 train_loss 0.0006386225431924686 test_loss 0.0028706492666970007\n",
            "Iteration: 31 train_loss 0.0006352083333088861 test_loss 0.002874470736060175\n",
            "Iteration: 32 train_loss 0.0006029926029441412 test_loss 0.002738031624176074\n",
            "Iteration: 33 train_loss 0.0006652780726047543 test_loss 0.0027267793630016968\n",
            "Iteration: 34 train_loss 0.0009896920280880294 test_loss 0.0030779191984038334\n",
            "Iteration: 35 train_loss 0.0007223105703208905 test_loss 0.00293681095354259\n",
            "Iteration: 36 train_loss 0.0006346425335019983 test_loss 0.002697672787689953\n",
            "Iteration: 37 train_loss 0.0006111258364398964 test_loss 0.0028141590646555414\n",
            "Iteration: 38 train_loss 0.0005988369014327569 test_loss 0.0027937640115851536\n",
            "Iteration: 39 train_loss 0.0006254393609803325 test_loss 0.0027742066122300457\n",
            "Iteration: 40 train_loss 0.0007343030398866782 test_loss 0.0028547986257763114\n",
            "Iteration: 41 train_loss 0.0006267847670339203 test_loss 0.0028958108559891116\n",
            "Iteration: 42 train_loss 0.0007590516007136709 test_loss 0.0029043645081401337\n",
            "Iteration: 43 train_loss 0.0006524071092523324 test_loss 0.0028571507573360577\n",
            "Iteration: 44 train_loss 0.000860252523367914 test_loss 0.002943711428088136\n",
            "Iteration: 45 train_loss 0.0005561070725282964 test_loss 0.0028146654622105416\n",
            "Iteration: 46 train_loss 0.0006484401739726309 test_loss 0.0029521252545237076\n",
            "Iteration: 47 train_loss 0.0006125147866744858 test_loss 0.002906455942138564\n",
            "Iteration: 48 train_loss 0.000610508480410014 test_loss 0.0027288976871204795\n",
            "Iteration: 49 train_loss 0.000575021251521927 test_loss 0.0028263137901376467\n",
            "Iteration: 50 train_loss 0.0006611054314513846 test_loss 0.00285934660496423\n",
            "Iteration: 51 train_loss 0.0005804042130572877 test_loss 0.002853118294297019\n",
            "Iteration: 52 train_loss 0.0005024171572586056 test_loss 0.0027449026092654094\n",
            "Iteration: 53 train_loss 0.0006740081601795586 test_loss 0.0029209546282800147\n",
            "Iteration: 54 train_loss 0.000564857021769664 test_loss 0.002706920822674874\n",
            "Iteration: 55 train_loss 0.0005344225607890015 test_loss 0.002880015894334065\n",
            "Iteration: 56 train_loss 0.0005485312148569695 test_loss 0.002839313765434781\n",
            "Iteration: 57 train_loss 0.0005777256473569044 test_loss 0.0028735786472680047\n",
            "Iteration: 58 train_loss 0.0004725707612427262 test_loss 0.0026984323340002447\n",
            "Iteration: 59 train_loss 0.0004901566289239174 test_loss 0.0027428925513959257\n",
            "Iteration: 60 train_loss 0.000478654692415148 test_loss 0.0028137836015957873\n",
            "Iteration: 61 train_loss 0.000489657142922321 test_loss 0.002653377847309457\n",
            "Iteration: 62 train_loss 0.00046350111697393006 test_loss 0.0026944385390379466\n",
            "Iteration: 63 train_loss 0.0005323005573397192 test_loss 0.002698243650229415\n",
            "Iteration: 64 train_loss 0.0005232224488281645 test_loss 0.0027432500428403728\n",
            "Iteration: 65 train_loss 0.0005580570362023233 test_loss 0.0027760270713770296\n",
            "Iteration: 66 train_loss 0.0005609847910818643 test_loss 0.00283533458787133\n",
            "Iteration: 67 train_loss 0.000511768630046087 test_loss 0.0026867466913245153\n",
            "Iteration: 68 train_loss 0.0006371761121651313 test_loss 0.0028101373791287187\n",
            "Iteration: 69 train_loss 0.000507370923878625 test_loss 0.0027015606356144417\n",
            "Iteration: 70 train_loss 0.00047374210929168234 test_loss 0.0026639992465788964\n",
            "Iteration: 71 train_loss 0.0005997195626453807 test_loss 0.0027504617828526534\n",
            "Iteration: 72 train_loss 0.0005021735802680875 test_loss 0.0025974014151870506\n",
            "Iteration: 73 train_loss 0.0004780301125720143 test_loss 0.0025718679589772364\n",
            "Iteration: 74 train_loss 0.00045985597874581194 test_loss 0.0026960023897117935\n",
            "Iteration: 75 train_loss 0.0006601391796721146 test_loss 0.002841497651388636\n",
            "Iteration: 76 train_loss 0.0004810109638735109 test_loss 0.0027611252917267848\n",
            "Iteration: 77 train_loss 0.0007312589928915259 test_loss 0.0030188237797119655\n",
            "Iteration: 78 train_loss 0.000517051494292294 test_loss 0.0026085027275257744\n",
            "Iteration: 79 train_loss 0.0005109634633602885 test_loss 0.0028305272426223382\n",
            "Iteration: 80 train_loss 0.0004783932371841123 test_loss 0.002590113930637017\n",
            "Iteration: 81 train_loss 0.00042789721956069113 test_loss 0.0026553706356935436\n",
            "Iteration: 82 train_loss 0.0004507687746809097 test_loss 0.0024834988689690363\n",
            "Iteration: 83 train_loss 0.0005029169153810168 test_loss 0.002684985634914483\n",
            "Iteration: 84 train_loss 0.0003762004535625844 test_loss 0.0025267083146900404\n",
            "Iteration: 85 train_loss 0.0004305857966149536 test_loss 0.0026359328476246446\n",
            "Iteration: 86 train_loss 0.00039381960790099886 test_loss 0.0026059494175569853\n",
            "Iteration: 87 train_loss 0.0004804329780502788 test_loss 0.002784921722195577\n",
            "Iteration: 88 train_loss 0.00044560236286391347 test_loss 0.00259165952593321\n",
            "Iteration: 89 train_loss 0.0004802913503226591 test_loss 0.0025160869445244316\n",
            "Iteration: 90 train_loss 0.0005237688868267772 test_loss 0.0026892235910054296\n",
            "Iteration: 91 train_loss 0.0005521761971370628 test_loss 0.0027533033753570635\n",
            "Iteration: 92 train_loss 0.0004371536272325708 test_loss 0.002570467917394126\n",
            "Iteration: 93 train_loss 0.0004808059769857209 test_loss 0.0025496329362795223\n",
            "Iteration: 94 train_loss 0.0005011238924150044 test_loss 0.0025722173013491556\n",
            "Iteration: 95 train_loss 0.0004769260872611388 test_loss 0.002584779056633124\n",
            "Iteration: 96 train_loss 0.0004920386564966369 test_loss 0.00254637253965484\n",
            "Iteration: 97 train_loss 0.0004827891370950965 test_loss 0.0026766179580590688\n",
            "Iteration: 98 train_loss 0.0004841593812064578 test_loss 0.0027487689440022223\n",
            "Iteration: 99 train_loss 0.00044949866157063904 test_loss 0.002542479263865971\n",
            "Iteration: 100 train_loss 0.000470351128387847 test_loss 0.0025315644052170683\n",
            "Iteration: 101 train_loss 0.0004489279820215112 test_loss 0.0026467908937775064\n",
            "Iteration: 102 train_loss 0.00038039917914526694 test_loss 0.0025021875444508623\n",
            "Iteration: 103 train_loss 0.00041115451628381073 test_loss 0.002641962310008239\n",
            "Iteration: 104 train_loss 0.00039321301179976825 test_loss 0.0025389093443664024\n",
            "Iteration: 105 train_loss 0.00039720350396237335 test_loss 0.002514996645913925\n",
            "Iteration: 106 train_loss 0.00038983484397855743 test_loss 0.002640253253048286\n",
            "Iteration: 107 train_loss 0.0004129228293701696 test_loss 0.002575885298938374\n",
            "Iteration: 108 train_loss 0.00038864765447215176 test_loss 0.002522996734114713\n",
            "Iteration: 109 train_loss 0.0004152700421400368 test_loss 0.0026119025169464294\n",
            "Iteration: 110 train_loss 0.00046674451805301943 test_loss 0.0025056812228285708\n",
            "Iteration: 111 train_loss 0.0003919586028738801 test_loss 0.0025880143402901012\n",
            "Iteration: 112 train_loss 0.0005288692057850616 test_loss 0.002748187253018841\n",
            "Iteration: 113 train_loss 0.0004849749983501776 test_loss 0.00257988044177182\n",
            "Iteration: 114 train_loss 0.0004988982315505078 test_loss 0.002549579210608499\n",
            "Iteration: 115 train_loss 0.0005075119282992091 test_loss 0.002597425765998196\n",
            "Iteration: 116 train_loss 0.0004771979324383816 test_loss 0.002864488029445056\n",
            "Iteration: 117 train_loss 0.0003982655148623356 test_loss 0.0024159609311027452\n",
            "Iteration: 118 train_loss 0.0004142984561137079 test_loss 0.002504605059584719\n",
            "Iteration: 119 train_loss 0.00035067929202341474 test_loss 0.0025272502716688905\n",
            "Iteration: 120 train_loss 0.00035891836487280673 test_loss 0.002575448997959029\n",
            "Iteration: 121 train_loss 0.0003462597665929934 test_loss 0.0025604479997127783\n",
            "Iteration: 122 train_loss 0.0003948975002761775 test_loss 0.002555921433668118\n",
            "Iteration: 123 train_loss 0.0004117634974439473 test_loss 0.002637652498378884\n",
            "Iteration: 124 train_loss 0.00047683002546060983 test_loss 0.0026105335891770665\n",
            "Iteration: 125 train_loss 0.0003913737510932454 test_loss 0.002621279234517715\n",
            "Iteration: 126 train_loss 0.00040621604760720706 test_loss 0.002561975699791219\n",
            "Iteration: 127 train_loss 0.0003503959032968851 test_loss 0.0024818092715577222\n",
            "Iteration: 128 train_loss 0.0003669897606111287 test_loss 0.00241417868892313\n",
            "Iteration: 129 train_loss 0.0003642998965612302 test_loss 0.002520557820389513\n",
            "Iteration: 130 train_loss 0.00033783561496723754 test_loss 0.002501220220437972\n",
            "Iteration: 131 train_loss 0.0004414167084178189 test_loss 0.0024693478808330838\n",
            "Iteration: 132 train_loss 0.0004388277056326236 test_loss 0.0024995814128487837\n",
            "Iteration: 133 train_loss 0.00039902231716647897 test_loss 0.002438562056340743\n",
            "Iteration: 134 train_loss 0.00040866689256896884 test_loss 0.0024129367957357317\n",
            "Iteration: 135 train_loss 0.00042711742329023156 test_loss 0.002433830981317442\n",
            "Iteration: 136 train_loss 0.0003611886410605318 test_loss 0.002486174118530471\n",
            "Iteration: 137 train_loss 0.0003825637234209959 test_loss 0.002566485109127825\n",
            "Iteration: 138 train_loss 0.0003319670580822276 test_loss 0.002408046493656002\n",
            "Iteration: 139 train_loss 0.00032620256946150523 test_loss 0.002405833660304779\n",
            "Iteration: 140 train_loss 0.00032315590918490975 test_loss 0.0023618487302883295\n",
            "Iteration: 141 train_loss 0.000314847653862671 test_loss 0.0024672912295500282\n",
            "Iteration: 142 train_loss 0.0003508748663686371 test_loss 0.002514682029868709\n",
            "Iteration: 143 train_loss 0.00035952193356934 test_loss 0.0025443689119128976\n",
            "Iteration: 144 train_loss 0.0003681778096506605 test_loss 0.00245220196666196\n",
            "Iteration: 145 train_loss 0.0004459899191715522 test_loss 0.002458344069964369\n",
            "Iteration: 146 train_loss 0.00040589780898396083 test_loss 0.002453501150739612\n",
            "Iteration: 147 train_loss 0.0003762561950376645 test_loss 0.002333480519155273\n",
            "Iteration: 148 train_loss 0.00039519189534379013 test_loss 0.002528874876588816\n",
            "Iteration: 149 train_loss 0.00040827119713261105 test_loss 0.002405926054052543\n",
            "Iteration: 150 train_loss 0.00038853611404192633 test_loss 0.0022886814767844044\n",
            "Iteration: 151 train_loss 0.0003849706665884393 test_loss 0.002491972903953865\n",
            "Iteration: 152 train_loss 0.0003648351493514686 test_loss 0.002328226633835584\n",
            "Iteration: 153 train_loss 0.000364909206473385 test_loss 0.0024313753201568034\n",
            "Iteration: 154 train_loss 0.0003208464638494964 test_loss 0.0024303018290083855\n",
            "Iteration: 155 train_loss 0.0002874177610162102 test_loss 0.002440833573928103\n",
            "Iteration: 156 train_loss 0.00031058494447885703 test_loss 0.002471246212735423\n",
            "Iteration: 157 train_loss 0.00029586299327396165 test_loss 0.0023947295994730666\n",
            "Iteration: 158 train_loss 0.00031607133581322463 test_loss 0.0025036064289452042\n",
            "Iteration: 159 train_loss 0.00032068481499057574 test_loss 0.0024350270359718706\n",
            "Iteration: 160 train_loss 0.0003267430431151297 test_loss 0.0023921055581013206\n",
            "Iteration: 161 train_loss 0.00035871732834493744 test_loss 0.0024721186418901198\n",
            "Iteration: 162 train_loss 0.0003451747863437049 test_loss 0.0025773856286832597\n",
            "Iteration: 163 train_loss 0.00034035283266954744 test_loss 0.0024025355851335917\n",
            "Iteration: 164 train_loss 0.00037091798015656725 test_loss 0.0024097254608932417\n",
            "Iteration: 165 train_loss 0.00037256166312242084 test_loss 0.002448799221383524\n",
            "Iteration: 166 train_loss 0.0004513014931338451 test_loss 0.0026021455450973008\n",
            "Iteration: 167 train_loss 0.0003674645578333487 test_loss 0.0024195328314817743\n",
            "Iteration: 168 train_loss 0.0003322775251338802 test_loss 0.0023371612223854754\n",
            "Iteration: 169 train_loss 0.00032900155335179683 test_loss 0.002353194595343666\n",
            "Iteration: 170 train_loss 0.0003148916447874702 test_loss 0.002498118554285611\n",
            "Iteration: 171 train_loss 0.00032315061313662835 test_loss 0.0024806853143672924\n",
            "Iteration: 172 train_loss 0.0003597739283577539 test_loss 0.002616123852931196\n",
            "Iteration: 173 train_loss 0.00032699035364203155 test_loss 0.002466427304170793\n",
            "Iteration: 174 train_loss 0.0003427009352890309 test_loss 0.0022920978171896422\n",
            "Iteration: 175 train_loss 0.0003169945164700039 test_loss 0.0024770895797701087\n",
            "Iteration: 176 train_loss 0.0003233613736180511 test_loss 0.002409710989013547\n",
            "Iteration: 177 train_loss 0.00038423775622504764 test_loss 0.0025118637313426007\n",
            "Iteration: 178 train_loss 0.0003416043514638053 test_loss 0.0024055433095782064\n",
            "Iteration: 179 train_loss 0.00035479148840143656 test_loss 0.0023858513341110665\n",
            "Iteration: 180 train_loss 0.000314077016931454 test_loss 0.0024395976724918\n",
            "Iteration: 181 train_loss 0.000318883165649216 test_loss 0.0025125465072051156\n",
            "Iteration: 182 train_loss 0.00029428461057250387 test_loss 0.0023887823408585973\n",
            "Iteration: 183 train_loss 0.00030809841615943393 test_loss 0.0023294207767321495\n",
            "Iteration: 184 train_loss 0.00033903551132728656 test_loss 0.0024319480507983826\n",
            "Iteration: 185 train_loss 0.0003180028562686251 test_loss 0.002337292258744128\n",
            "Iteration: 186 train_loss 0.00029670686465882077 test_loss 0.002385099189268658\n",
            "Iteration: 187 train_loss 0.00030786395824785966 test_loss 0.0023195596440928057\n",
            "Iteration: 188 train_loss 0.0003537822427460924 test_loss 0.00239274736304651\n",
            "Iteration: 189 train_loss 0.0003668896645346346 test_loss 0.0024459992255287943\n",
            "Iteration: 190 train_loss 0.000368680714139676 test_loss 0.0025837733719527023\n",
            "Iteration: 191 train_loss 0.00031346991563623304 test_loss 0.0023348031390924007\n",
            "Iteration: 192 train_loss 0.00036460087964466464 test_loss 0.0023868216539995046\n",
            "Iteration: 193 train_loss 0.0002995186988603867 test_loss 0.0023175429632829037\n",
            "Iteration: 194 train_loss 0.0003590269545384217 test_loss 0.0024148806605808204\n",
            "Iteration: 195 train_loss 0.0003042020615491007 test_loss 0.002348584635910811\n",
            "Iteration: 196 train_loss 0.0003406163473603859 test_loss 0.002436445503917639\n",
            "Iteration: 197 train_loss 0.000305352223100878 test_loss 0.0023998462293093326\n",
            "Iteration: 198 train_loss 0.00029719075015843067 test_loss 0.002326027066374081\n",
            "Iteration: 199 train_loss 0.0003179016690410208 test_loss 0.002477945265127346\n",
            "Iteration: 200 train_loss 0.0003149008276523091 test_loss 0.0023340350708167534\n",
            "Training Completed !\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.9)\n",
        "\n",
        "epoch = 200\n",
        "\n",
        "for i in range(epoch):\n",
        "    for j, data in enumerate(train_loader, 0):\n",
        "                \n",
        "        inputs = data[0].to(device)\n",
        "        labels = data[1].to(device)\n",
        "    \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predictions = net(inputs)\n",
        "        loss = loss_fcn(predictions.float(), labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    scheduler.step()    \n",
        "    print(\"Iteration:\", i + 1, \"train_loss\", compute_loss(net, train_loader), \"test_loss\", compute_loss(net, test_loader))\n",
        "\n",
        "print('Training Completed !')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfrDcKArAb0o"
      },
      "outputs": [],
      "source": [
        "# Save model and results\n",
        "\n",
        "torch.save(net.state_dict(), \"./drive/MyDrive/boostnet_labeldata/model_2/torch_model_2\")\n",
        "\n",
        "test_result = []\n",
        "dataiter = iter(test_loader)\n",
        "for i in range(num_batches):\n",
        "  image, label = dataiter.next()\n",
        "  prediction = net(image.to(device))\n",
        "  for j in range(b_size):\n",
        "    test_result.append(prediction[j].tolist())\n",
        "np.savetxt(\"./drive/MyDrive/boostnet_labeldata/model_2/test_all_angles.csv\", test_result, delimiter =\", \", fmt ='% s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-sco2AcAz6j",
        "outputId": "662046fc-cb17-4fe7-e282-7d26ceb6d1d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 prediction: [6.255367398262008, 9.251432418823235, 10.682581365108486]\n",
            "1 groundtruth: [43.423, 15.872, 40.687]\n",
            "1 difference: [37.1676326   6.62056758 30.00441863]\n",
            "SMAPE: 0.5848601967132975\n",
            "\n",
            "\n",
            "2 prediction: [10.86186826229094, 31.001438498497006, 18.002442419528958]\n",
            "2 groundtruth: [34.609, 33.592, 12.048]\n",
            "2 difference: [23.74713174  2.5905615   5.95444242]\n",
            "SMAPE: 0.23046921075513266\n",
            "\n",
            "\n",
            "3 prediction: [7.405831217765808, 23.282840251922597, 11.662075817584991]\n",
            "3 groundtruth: [26.437, 15.781, 8.0784]\n",
            "3 difference: [19.03116878  7.50184025  3.58367582]\n",
            "SMAPE: 0.325068668961368\n",
            "\n",
            "\n",
            "4 prediction: [25.14207512140274, 45.31782567501068, 28.88578176498412]\n",
            "4 groundtruth: [48.061, 29.951, 19.867]\n",
            "4 difference: [22.91892488 15.36682568  9.01878176]\n",
            "SMAPE: 0.23985097455469753\n",
            "\n",
            "\n",
            "5 prediction: [17.0439738035202, 11.180753409862511, 21.227356195449822]\n",
            "5 groundtruth: [41.524, 19.011, 23.36]\n",
            "5 difference: [24.4800262   7.83024659  2.1326438 ]\n",
            "SMAPE: 0.2582952375911213\n",
            "\n",
            "\n",
            "6 prediction: [18.25922772288322, 6.5926169604063, 19.160471409559236]\n",
            "6 groundtruth: [49.586, 7.2823, 39.244]\n",
            "6 difference: [31.32677228  0.68968304 20.08352859]\n",
            "SMAPE: 0.3718117869641761\n",
            "\n",
            "\n",
            "7 prediction: [13.713489621877663, 18.397046327590925, 12.819646149873732]\n",
            "7 groundtruth: [53.32, 13.642, 30.345]\n",
            "7 difference: [39.60651038  4.75504633 17.52535385]\n",
            "SMAPE: 0.43509657350084474\n",
            "\n",
            "\n",
            "8 prediction: [11.077820956706994, 4.367355108261102, 25.34597933292389]\n",
            "8 groundtruth: [55.438, 11.448, 31.692]\n",
            "8 difference: [44.36017904  7.08064489  6.34602067]\n",
            "SMAPE: 0.414631518983734\n",
            "\n",
            "\n",
            "9 prediction: [7.3540323972702, 5.232161991298193, 9.024939313530911]\n",
            "9 groundtruth: [32.927, 15.759, 16.901]\n",
            "9 difference: [25.5729676  10.52683801  7.87606069]\n",
            "SMAPE: 0.5043211870581809\n",
            "\n",
            "\n",
            "10 prediction: [7.886217534542083, 8.545210808515542, 5.911636278033251]\n",
            "10 groundtruth: [52.848, 18.095, 28.915]\n",
            "10 difference: [44.96178247  9.54978919 23.00336372]\n",
            "SMAPE: 0.6343229137917895\n",
            "\n",
            "\n",
            "11 prediction: [9.658696353435504, 8.027767091989512, 6.6754053533077204]\n",
            "11 groundtruth: [27.372, 13.871, 10.869]\n",
            "11 difference: [17.71330365  5.84323291  4.19359465]\n",
            "SMAPE: 0.36287076405538304\n",
            "\n",
            "\n",
            "12 prediction: [31.479716598987565, 18.88963401317596, 15.264254361391055]\n",
            "12 groundtruth: [72.294, 19.667, 38.109]\n",
            "12 difference: [40.8142834   0.77736599 22.84474564]\n",
            "SMAPE: 0.32925502335612417\n",
            "\n",
            "\n",
            "13 prediction: [12.091234624385832, 9.519832357764228, 22.17090100049971]\n",
            "13 groundtruth: [80.771, 19.289, 47.135]\n",
            "13 difference: [68.67976538  9.76916764 24.964099  ]\n",
            "SMAPE: 0.5414947839508336\n",
            "\n",
            "\n",
            "14 prediction: [12.353971749544133, 28.96406203508377, 30.285825133323655]\n",
            "14 groundtruth: [37.114, 11.177, 26.81]\n",
            "14 difference: [24.76002825 17.78706204  3.47582513]\n",
            "SMAPE: 0.31371091426905484\n",
            "\n",
            "\n",
            "15 prediction: [19.866511970758424, 15.436236262321458, 7.406181246042252]\n",
            "15 groundtruth: [40.173, 12.841, 29.482]\n",
            "15 difference: [20.30648803  2.59523626 22.07581875]\n",
            "SMAPE: 0.35923140752234334\n",
            "\n",
            "\n",
            "16 prediction: [13.822101652622221, 22.35929533839225, 11.870158910751343]\n",
            "16 groundtruth: [46.138, 15.795, 29.611]\n",
            "16 difference: [32.31589835  6.56429534 17.74084109]\n",
            "SMAPE: 0.4056077173034307\n",
            "\n",
            "\n",
            "17 prediction: [18.171630799770348, 22.344413101673112, 14.707981646060942]\n",
            "17 groundtruth: [42.282, 16.976, 28.076]\n",
            "17 difference: [24.1103692   5.3684131  13.36801835]\n",
            "SMAPE: 0.3005569170257906\n",
            "\n",
            "\n",
            "18 prediction: [4.433789737522602, 10.801888033747662, 6.208643317222584]\n",
            "18 groundtruth: [44.344, 19.249, 26.735]\n",
            "18 difference: [39.91021026  8.44711197 20.52635668]\n",
            "SMAPE: 0.616285662145016\n",
            "\n",
            "\n",
            "19 prediction: [19.206042140722264, 5.380814373493194, 4.352158382534964]\n",
            "19 groundtruth: [35.073, 0.92806, 8.147]\n",
            "19 difference: [15.86695786  4.45275437  3.79484162]\n",
            "SMAPE: 0.3299427961004379\n",
            "\n",
            "\n",
            "20 prediction: [29.975555241107926, 27.046880722045888, 29.111186563968655]\n",
            "20 groundtruth: [38.726, 4.013, 4.7835]\n",
            "20 difference: [ 8.75044476 23.03388072 24.32768656]\n",
            "SMAPE: 0.4198237311090628\n",
            "\n",
            "\n",
            "21 prediction: [10.893981009721752, 19.794245213270177, 34.79536145925522]\n",
            "21 groundtruth: [36.239, 0.0, 35.781]\n",
            "21 difference: [25.34501899 19.79424521  0.98563854]\n",
            "SMAPE: 0.3354450856284698\n",
            "\n",
            "\n",
            "22 prediction: [15.568184852600096, 17.874561399221413, 13.218042701482759]\n",
            "22 groundtruth: [39.932, 38.527, 34.061]\n",
            "22 difference: [24.36381515 20.6524386  20.8429573 ]\n",
            "SMAPE: 0.41373843841178315\n",
            "\n",
            "\n",
            "23 prediction: [26.87409549951552, 37.969286441802964, 17.688641399145126]\n",
            "23 groundtruth: [41.671, 0.47462, 38.443]\n",
            "23 difference: [14.7969045  37.49466644 20.7543586 ]\n",
            "SMAPE: 0.44780309865920304\n",
            "\n",
            "\n",
            "24 prediction: [10.884007215499878, 13.727973550558085, 16.418442428112026]\n",
            "24 groundtruth: [44.163, 18.397, 19.388]\n",
            "24 difference: [33.27899278  4.66902645  2.96955757]\n",
            "SMAPE: 0.33272159247988947\n",
            "\n",
            "\n",
            "25 prediction: [15.128678083419793, 16.42625570297241, 28.883635997772203]\n",
            "25 groundtruth: [41.083, 17.512, 19.412]\n",
            "25 difference: [25.95432192  1.0857443   9.471636  ]\n",
            "SMAPE: 0.2637260424317041\n",
            "\n",
            "\n",
            "26 prediction: [19.443056881427765, 1.17035625502467, 5.702763944864268]\n",
            "26 groundtruth: [36.844, 13.085, 12.971]\n",
            "26 difference: [17.40094312 11.91464374  7.26823606]\n",
            "SMAPE: 0.4100581768409412\n",
            "\n",
            "\n",
            "27 prediction: [17.775799781084046, 19.492899030446992, 7.70926147699356]\n",
            "27 groundtruth: [11.732, 7.6203, 5.0782]\n",
            "27 difference: [ 6.04379978 11.87259903  2.63106148]\n",
            "SMAPE: 0.2960368261031968\n",
            "\n",
            "\n",
            "28 prediction: [24.4942009449005, 54.62661445140838, 38.12354296445846]\n",
            "28 groundtruth: [11.594, 8.4509, 4.6449]\n",
            "28 difference: [12.90020094 46.17571445 33.47864296]\n",
            "SMAPE: 0.6520950237046726\n",
            "\n",
            "\n",
            "29 prediction: [10.194593667984, 9.456282779574384, 7.482996359467506]\n",
            "29 groundtruth: [9.7651, 6.6961, 1.0907]\n",
            "29 difference: [0.42949367 2.76018278 6.39229636]\n",
            "SMAPE: 0.21443005693121475\n",
            "\n",
            "\n",
            "30 prediction: [9.531223028898228, 9.538660794496536, 32.533814013004296]\n",
            "30 groundtruth: [14.839, 11.337, 6.0558]\n",
            "30 difference: [ 5.30777697  1.79833921 26.47801401]\n",
            "SMAPE: 0.40059558368875375\n",
            "\n",
            "\n",
            "31 prediction: [17.889273315668106, 17.705870568752275, 13.382906019687647]\n",
            "31 groundtruth: [53.215, 44.772, 7.0978]\n",
            "31 difference: [35.32572668 27.06612943  6.28510602]\n",
            "SMAPE: 0.4457723726259332\n",
            "\n",
            "\n",
            "32 prediction: [21.56435027718543, 36.39919370412825, 17.923255562782277]\n",
            "32 groundtruth: [57.688, 48.546, 6.1322]\n",
            "32 difference: [36.12364972 12.1468063  11.79105556]\n",
            "SMAPE: 0.31904677071240994\n",
            "\n",
            "\n",
            "33 prediction: [4.997976645827286, 5.859498828649518, 14.190492331981657]\n",
            "33 groundtruth: [64.785, 46.901, 5.3344]\n",
            "33 difference: [59.78702335 41.04150117  8.85609233]\n",
            "SMAPE: 0.7720551629545683\n",
            "\n",
            "\n",
            "34 prediction: [20.610478967428204, 31.53968811035156, 27.620455026626587]\n",
            "34 groundtruth: [46.155, 23.192, 38.108]\n",
            "34 difference: [25.54452103  8.34768811 10.48754497]\n",
            "SMAPE: 0.23703889252694485\n",
            "\n",
            "\n",
            "35 prediction: [14.665073007345192, 32.51723796129226, 14.531234800815575]\n",
            "35 groundtruth: [59.534, 13.197, 0.36848]\n",
            "35 difference: [44.86892699 19.32023796 14.1627548 ]\n",
            "SMAPE: 0.5811895349693741\n",
            "\n",
            "\n",
            "36 prediction: [9.468317180871953, 8.448062539100635, 32.16986507177352]\n",
            "36 groundtruth: [61.015, 24.754, 13.966]\n",
            "36 difference: [51.54668282 16.30593746 18.20386507]\n",
            "SMAPE: 0.5743944089599631\n",
            "\n",
            "\n",
            "37 prediction: [18.483145236968994, 33.7368008494377, 33.378342390060425]\n",
            "37 groundtruth: [55.311, 40.749, 24.792]\n",
            "37 difference: [36.82785476  7.01219915  8.58634239]\n",
            "SMAPE: 0.2539419861824495\n",
            "\n",
            "\n",
            "38 prediction: [16.793303936719877, 27.43954002857207, 18.823058903217312]\n",
            "38 groundtruth: [26.723, 6.0564, 16.887]\n",
            "38 difference: [ 9.92969606 21.38314003  1.9360589 ]\n",
            "SMAPE: 0.29496287911944447\n",
            "\n",
            "\n",
            "39 prediction: [20.8805277943611, 57.438985705375664, 40.02458542585373]\n",
            "39 groundtruth: [17.087, 15.306, 15.63]\n",
            "39 difference: [ 3.79352779 42.13298571 24.39458543]\n",
            "SMAPE: 0.42268633269275413\n",
            "\n",
            "\n",
            "40 prediction: [10.152182579040522, 15.222287178039545, 6.328460276126856]\n",
            "40 groundtruth: [15.209, 0.0, 2.6406]\n",
            "40 difference: [ 5.05681742 15.22228718  3.68786028]\n",
            "SMAPE: 0.4836678340957517\n",
            "\n",
            "\n",
            "41 prediction: [15.666768103837967, 15.241636633872979, 18.463937938213338]\n",
            "41 groundtruth: [16.007, 9.4175, 1.9516]\n",
            "41 difference: [ 0.3402319   5.82413663 16.51233794]\n",
            "SMAPE: 0.29546796882905296\n",
            "\n",
            "\n",
            "42 prediction: [20.5244806408882, 42.42252320051193, 26.698054075241075]\n",
            "42 groundtruth: [14.189, 3.8682, 8.1103]\n",
            "42 difference: [ 6.33548064 38.5543232  18.58775408]\n",
            "SMAPE: 0.5481060004074053\n",
            "\n",
            "\n",
            "43 prediction: [7.399597093462944, 11.846892088651645, 12.725016474723803]\n",
            "43 groundtruth: [47.958, 40.946, 9.6259]\n",
            "43 difference: [40.55840291 29.09910791  3.09911647]\n",
            "SMAPE: 0.5575160430373242\n",
            "\n",
            "\n",
            "44 prediction: [19.180860221385952, 24.36455100774764, 11.291257739067065]\n",
            "44 groundtruth: [44.699, 39.578, 12.931]\n",
            "44 difference: [25.51813978 15.21344899  1.63974226]\n",
            "SMAPE: 0.278676860684021\n",
            "\n",
            "\n",
            "45 prediction: [9.347544014453874, 17.512563765048967, 11.710723042488096]\n",
            "45 groundtruth: [51.466, 46.317, 14.21]\n",
            "45 difference: [42.11845599 28.80443623  2.49927696]\n",
            "SMAPE: 0.487648120914344\n",
            "\n",
            "\n",
            "46 prediction: [16.81117281317711, 1.053021512925612, 13.709294646978366]\n",
            "46 groundtruth: [39.545, 0.0, 0.0]\n",
            "46 difference: [22.73382719  1.05302151 13.70929465]\n",
            "SMAPE: 0.5272348145771131\n",
            "\n",
            "\n",
            "47 prediction: [18.892013132572163, 18.376858681440353, 10.319769009947771]\n",
            "47 groundtruth: [23.339, 21.783, 21.305]\n",
            "47 difference: [ 4.44698687  3.40614132 10.98523099]\n",
            "SMAPE: 0.16522609564705307\n",
            "\n",
            "\n",
            "48 prediction: [7.846684455871566, 9.89006906747817, 8.09737108647822]\n",
            "48 groundtruth: [64.048, 50.958, 16.981]\n",
            "48 difference: [56.20131554 41.06793093  8.88362891]\n",
            "SMAPE: 0.672615124576052\n",
            "\n",
            "\n",
            "49 prediction: [21.400858908891664, 7.479679808020591, 19.675694257020936]\n",
            "49 groundtruth: [33.589, 30.393, 12.379]\n",
            "49 difference: [12.18814109 22.91332019  7.29669426]\n",
            "SMAPE: 0.3394099799581377\n",
            "\n",
            "\n",
            "50 prediction: [17.483110427856438, 18.66002485156058, 12.142720967531202]\n",
            "50 groundtruth: [54.345, 24.119, 33.424]\n",
            "50 difference: [36.86188957  5.45897515 21.28127903]\n",
            "SMAPE: 0.3970819286200683\n",
            "\n",
            "\n",
            "51 prediction: [14.050141721963875, 22.414355725049965, 24.20065462589264]\n",
            "51 groundtruth: [53.508, 24.125, 27.788]\n",
            "51 difference: [39.45785828  1.71064427  3.58734537]\n",
            "SMAPE: 0.26947368801371924\n",
            "\n",
            "\n",
            "52 prediction: [14.485314041376101, 20.550832003355023, 17.0633178949356]\n",
            "52 groundtruth: [59.517, 23.963, 36.389]\n",
            "52 difference: [45.03168596  3.412168   19.32568211]\n",
            "SMAPE: 0.39408118504861156\n",
            "\n",
            "\n",
            "53 prediction: [13.995541334152207, 21.707016974687573, 13.269834816455827]\n",
            "53 groundtruth: [66.547, 28.413, 36.873]\n",
            "53 difference: [52.55145867  6.70598303 23.60316518]\n",
            "SMAPE: 0.458286146460704\n",
            "\n",
            "\n",
            "54 prediction: [24.781036376953114, 31.293144822120663, 15.039506703615174]\n",
            "54 groundtruth: [61.199, 21.789, 37.504]\n",
            "54 difference: [36.41796362  9.50414482 22.4644933 ]\n",
            "SMAPE: 0.35691321322508945\n",
            "\n",
            "\n",
            "55 prediction: [9.603322148323045, 23.112477064132687, 17.43223160505294]\n",
            "55 groundtruth: [70.773, 23.06, 45.194]\n",
            "55 difference: [6.11696779e+01 5.24770641e-02 2.77617684e+01]\n",
            "SMAPE: 0.4703787964311038\n",
            "\n",
            "\n",
            "56 prediction: [9.843346327543253, 14.739001393318164, 16.626058816909786]\n",
            "56 groundtruth: [31.523, 22.619, 10.194]\n",
            "56 difference: [21.67965367  7.87999861  6.43205882]\n",
            "SMAPE: 0.3410101233850607\n",
            "\n",
            "\n",
            "57 prediction: [11.523625552654254, 14.513686448335633, 18.559121489524838]\n",
            "57 groundtruth: [43.055, 32.551, 10.937]\n",
            "57 difference: [31.53137445 18.03731355  7.62212149]\n",
            "SMAPE: 0.43610688231828876\n",
            "\n",
            "\n",
            "58 prediction: [19.743409305810918, 24.92541432380675, 16.050041019916524]\n",
            "58 groundtruth: [52.21, 25.463, 0.0]\n",
            "58 difference: [32.46659069  0.53758568 16.05004102]\n",
            "SMAPE: 0.354458822522007\n",
            "\n",
            "\n",
            "59 prediction: [29.996597170829773, 46.1683702468872, 20.626593679189675]\n",
            "59 groundtruth: [55.55, 30.816, 0.0]\n",
            "59 difference: [25.55340283 15.35237025 20.62659368]\n",
            "SMAPE: 0.33595318908341987\n",
            "\n",
            "\n",
            "60 prediction: [25.182528197765347, 38.69788706302642, 20.721212625503536]\n",
            "60 groundtruth: [17.453, 0.0, 6.1536]\n",
            "60 difference: [ 7.7295282  38.69788706 14.56761263]\n",
            "SMAPE: 0.5636819775885119\n",
            "\n",
            "\n",
            "61 prediction: [22.655522525310506, 4.696393422782411, 30.894834101200093]\n",
            "61 groundtruth: [28.912, 18.141, 6.0927]\n",
            "61 difference: [ 6.25647747 13.44460658 24.8021341 ]\n",
            "SMAPE: 0.39951736525602727\n",
            "\n",
            "\n",
            "62 prediction: [15.5912035703659, 23.1610894203186, 19.678219556808457]\n",
            "62 groundtruth: [35.869, 17.308, 6.6546]\n",
            "62 difference: [20.27779643  5.85308942 13.02361956]\n",
            "SMAPE: 0.33108241146154965\n",
            "\n",
            "\n",
            "63 prediction: [22.879639863967896, 34.998890161514275, 14.253365993499756]\n",
            "63 groundtruth: [42.281, 25.543, 5.0576]\n",
            "63 difference: [19.40136014  9.45589016  9.19576599]\n",
            "SMAPE: 0.26241017102342723\n",
            "\n",
            "\n",
            "64 prediction: [9.534495323896397, 4.087873622775078, 43.5265901684761]\n",
            "64 groundtruth: [35.127, 24.566, 3.3988]\n",
            "64 difference: [25.59250468 20.47812638 40.12779017]\n",
            "SMAPE: 0.7168818781263465\n",
            "\n",
            "\n",
            "65 prediction: [19.674198925495144, 19.133694916963577, 18.723959326744076]\n",
            "65 groundtruth: [33.555, 22.95, 8.9195]\n",
            "65 difference: [13.88080107  3.81630508  9.80445933]\n",
            "SMAPE: 0.2236693328602539\n",
            "\n",
            "\n",
            "66 prediction: [10.703204870223997, 10.626933574676503, 5.764742419123638]\n",
            "66 groundtruth: [41.763, 36.114, 9.8227]\n",
            "66 difference: [31.05979513 25.48706643  4.05795758]\n",
            "SMAPE: 0.5279414644822229\n",
            "\n",
            "\n",
            "67 prediction: [5.279569365084156, 4.493979513645156, 10.741235911846147]\n",
            "67 groundtruth: [30.783, 26.018, 10.005]\n",
            "67 difference: [25.50343063 21.52402049  0.73623591]\n",
            "SMAPE: 0.546991041682346\n",
            "\n",
            "\n",
            "68 prediction: [11.037886887788765, 6.862459257245052, 8.961991220712655]\n",
            "68 groundtruth: [44.123, 16.449, 25.076]\n",
            "68 difference: [33.08511311  9.58654074 16.11400878]\n",
            "SMAPE: 0.5224912129021018\n",
            "\n",
            "\n",
            "69 prediction: [11.4846222102642, 14.246109277009957, 38.44327837228774]\n",
            "69 groundtruth: [58.912, 20.255, 33.227]\n",
            "69 difference: [47.42737779  6.00889072  5.21627837]\n",
            "SMAPE: 0.33218104984965546\n",
            "\n",
            "\n",
            "70 prediction: [7.606437653303137, 13.599513173103318, 10.683538243174548]\n",
            "70 groundtruth: [65.858, 23.355, 38.382]\n",
            "70 difference: [58.25156235  9.75548683 27.69846176]\n",
            "SMAPE: 0.6000929086505956\n",
            "\n",
            "\n",
            "71 prediction: [31.362683773040768, 61.86845004558563, 33.53615552186966]\n",
            "71 groundtruth: [65.326, 18.936, 37.521]\n",
            "71 difference: [33.96331623 42.93245005  3.98484448]\n",
            "SMAPE: 0.32540944114482423\n",
            "\n",
            "\n",
            "72 prediction: [22.593804895877835, 6.053595542907714, 24.41345304250717]\n",
            "72 groundtruth: [49.088, 30.214, 34.736]\n",
            "72 difference: [26.4941951  24.16040446 10.32254696]\n",
            "SMAPE: 0.36491660623831795\n",
            "\n",
            "\n",
            "73 prediction: [5.619905479252332, 3.18129032850264, 7.987485006451601]\n",
            "73 groundtruth: [59.096, 34.551, 34.973]\n",
            "73 difference: [53.47609452 31.36970967 26.98551499]\n",
            "SMAPE: 0.7690828261394103\n",
            "\n",
            "\n",
            "74 prediction: [31.968954205513, 35.19834458827972, 17.954099625349045]\n",
            "74 groundtruth: [31.407, 17.617, 2.7552]\n",
            "74 difference: [ 0.56195421 17.58134459 15.19889963]\n",
            "SMAPE: 0.2435504212849356\n",
            "\n",
            "\n",
            "75 prediction: [14.542597979307162, 5.444972813129418, 19.88188505172729]\n",
            "75 groundtruth: [37.5, 16.45, 0.0]\n",
            "75 difference: [22.95740202 11.00502719 19.88188505]\n",
            "SMAPE: 0.5739141607123289\n",
            "\n",
            "\n",
            "76 prediction: [14.159856140613542, 20.567708462476727, 13.897757381200776]\n",
            "76 groundtruth: [30.367, 18.7, 1.9574]\n",
            "76 difference: [16.20714386  1.86770846 11.94035738]\n",
            "SMAPE: 0.3012071594920818\n",
            "\n",
            "\n",
            "77 prediction: [19.711096733808503, 62.43237912654877, 37.95164823532104]\n",
            "77 groundtruth: [47.206, 20.607, 22.99]\n",
            "77 difference: [27.49490327 41.82537913 14.96164824]\n",
            "SMAPE: 0.3996333821813657\n",
            "\n",
            "\n",
            "78 prediction: [23.026608824729905, 49.13275301456451, 43.66143554449081]\n",
            "78 groundtruth: [58.791, 25.708, 30.058]\n",
            "78 difference: [35.76439118 23.42475301 13.60343554]\n",
            "SMAPE: 0.31597046486671904\n",
            "\n",
            "\n",
            "79 prediction: [9.285130351781838, 9.642571583390225, 5.57283740490675]\n",
            "79 groundtruth: [60.008, 21.901, 28.064]\n",
            "79 difference: [50.72286965 12.25842842 22.4911626 ]\n",
            "SMAPE: 0.6356080242951319\n",
            "\n",
            "\n",
            "80 prediction: [20.264868289232243, 15.59752821922302, 27.108139693737026]\n",
            "80 groundtruth: [62.854, 26.723, 25.947]\n",
            "80 difference: [42.58913171 11.12547178  1.16113969]\n",
            "SMAPE: 0.30743654317306646\n",
            "\n",
            "\n",
            "81 prediction: [12.396547794342041, 3.004136458039278, 8.327031210064872]\n",
            "81 groundtruth: [62.483, 20.006, 57.358]\n",
            "81 difference: [50.08645221 17.00186354 49.03096879]\n",
            "SMAPE: 0.7098852913133307\n",
            "\n",
            "\n",
            "82 prediction: [22.863028943538666, 41.39533638954162, 25.64439386129379]\n",
            "82 groundtruth: [40.022, 14.956, 29.095]\n",
            "82 difference: [17.15897106 26.43933639  3.45060614]\n",
            "SMAPE: 0.2704337305529091\n",
            "\n",
            "\n",
            "83 prediction: [14.968216270208359, 15.152533650398249, 18.630921542644494]\n",
            "83 groundtruth: [48.059, 14.641, 0.0]\n",
            "83 difference: [33.09078373  0.51153365 18.63092154]\n",
            "SMAPE: 0.46866267896266783\n",
            "\n",
            "\n",
            "84 prediction: [14.414979815483093, 31.77786558866501, 33.917074799537644]\n",
            "84 groundtruth: [43.604, 15.28, 0.0]\n",
            "84 difference: [29.18902018 16.49786559 33.9170748 ]\n",
            "SMAPE: 0.5727154141423278\n",
            "\n",
            "\n",
            "85 prediction: [16.14943832159041, 16.671763658523545, 33.901528716087334]\n",
            "85 groundtruth: [44.031, 18.532, 0.0]\n",
            "85 difference: [27.88156168  1.86023634 33.90152872]\n",
            "SMAPE: 0.49226876309748363\n",
            "\n",
            "\n",
            "86 prediction: [15.318177491426454, 26.578282713890076, 17.185776829719533]\n",
            "86 groundtruth: [50.772, 26.388, 21.877]\n",
            "86 difference: [35.45382251  0.19028271  4.69122317]\n",
            "SMAPE: 0.25509437781948435\n",
            "\n",
            "\n",
            "87 prediction: [16.885983645915985, 28.696181774139394, 17.428617328405373]\n",
            "87 groundtruth: [50.219, 36.091, 6.1617]\n",
            "87 difference: [33.33301635  7.39481823 11.26691733]\n",
            "SMAPE: 0.33440906646999585\n",
            "\n",
            "\n",
            "88 prediction: [10.915773957967751, 2.973676286637774, 19.925697594881054]\n",
            "88 groundtruth: [53.845, 32.721, 6.4581]\n",
            "88 difference: [42.92922604 29.74732371 13.46759759]\n",
            "SMAPE: 0.6791600298614969\n",
            "\n",
            "\n",
            "89 prediction: [15.302300155162811, 10.977184474468217, 14.748173207044596]\n",
            "89 groundtruth: [40.601, 28.816, 0.0]\n",
            "89 difference: [25.29869984 17.83881553 14.74817321]\n",
            "SMAPE: 0.5241148798977159\n",
            "\n",
            "\n",
            "90 prediction: [16.31411790847778, 6.8765556067228255, 36.289638876914964]\n",
            "90 groundtruth: [43.718, 31.776, 28.124]\n",
            "90 difference: [27.40388209 24.89944439  8.16563888]\n",
            "SMAPE: 0.37075163117774557\n",
            "\n",
            "\n",
            "91 prediction: [22.747761011123657, 15.745033621788012, 9.960121661424624]\n",
            "91 groundtruth: [28.278, 22.203, 20.417]\n",
            "91 difference: [ 5.53023899  6.45796638 10.45687834]\n",
            "SMAPE: 0.1880595843127919\n",
            "\n",
            "\n",
            "92 prediction: [16.354426145553575, 55.30083060264587, 28.61955374479294]\n",
            "92 groundtruth: [26.258, 13.556, 22.831]\n",
            "92 difference: [ 9.90357385 41.7448306   5.78855374]\n",
            "SMAPE: 0.35254741598386374\n",
            "\n",
            "\n",
            "93 prediction: [21.335277557373047, 49.22801971435546, 27.872303724288937]\n",
            "93 groundtruth: [12.784, 5.228, 7.7087]\n",
            "93 difference: [ 8.55127756 44.00001971 20.16360372]\n",
            "SMAPE: 0.585672256765687\n",
            "\n",
            "\n",
            "94 prediction: [7.631744965910911, 10.744064301252347, 13.099505156278596]\n",
            "94 groundtruth: [14.026, 2.3143, 5.1225]\n",
            "94 difference: [6.39425503 8.4297643  7.97700516]\n",
            "SMAPE: 0.4307109299216628\n",
            "\n",
            "\n",
            "95 prediction: [7.9091001302003825, 2.07708002999424, 6.891576647758471]\n",
            "95 groundtruth: [11.288, 2.2182, 7.1472]\n",
            "95 difference: [3.37889987 0.14111997 0.25562335]\n",
            "SMAPE: 0.10060023492925813\n",
            "\n",
            "\n",
            "96 prediction: [21.961094588041302, 13.715292066335676, 30.392265915870663]\n",
            "96 groundtruth: [16.797, 0.0, 11.799]\n",
            "96 difference: [ 5.16409459 13.71529207 18.59326592]\n",
            "SMAPE: 0.39584630115702774\n",
            "\n",
            "\n",
            "97 prediction: [20.795552730560285, 35.29916882514952, 20.268117785453796]\n",
            "97 groundtruth: [28.399, 26.692, 16.704]\n",
            "97 difference: [7.60344727 8.60716883 3.56411779]\n",
            "SMAPE: 0.1334707226291798\n",
            "\n",
            "\n",
            "98 prediction: [16.281445920467362, 20.797569751739488, 19.992369264364243]\n",
            "98 groundtruth: [19.321, 0.041317, 16.482]\n",
            "98 difference: [ 3.03955408 20.75625275  3.51036926]\n",
            "SMAPE: 0.2938811796770037\n",
            "\n",
            "\n",
            "99 prediction: [14.906414151191699, 27.30654805898666, 20.482901036739342]\n",
            "99 groundtruth: [19.953, 17.483, 19.66]\n",
            "99 difference: [5.04658585 9.82354806 0.82290104]\n",
            "SMAPE: 0.13100251151605735\n",
            "\n",
            "\n",
            "100 prediction: [18.64921018481253, 15.726404339075089, 17.39675402641296]\n",
            "100 groundtruth: [20.409, 15.746, 19.964]\n",
            "100 difference: [1.75978982 0.01959566 2.56724597]\n",
            "SMAPE: 0.04028711015629533\n",
            "\n",
            "\n",
            "101 prediction: [14.796739965677256, 4.996186271309844, 16.43165364861488]\n",
            "101 groundtruth: [20.49, 20.438, 15.767]\n",
            "101 difference: [ 5.69326003 15.44181373  0.66465365]\n",
            "SMAPE: 0.2346085447057179\n",
            "\n",
            "\n",
            "102 prediction: [23.180130422115315, 49.46153283119202, 30.46812683343887]\n",
            "102 groundtruth: [25.651, 18.789, 18.306]\n",
            "102 difference: [ 2.47086958 30.67253283 12.16212683]\n",
            "SMAPE: 0.27316218034245165\n",
            "\n",
            "\n",
            "103 prediction: [22.016046345233903, 27.62053549289703, 10.447152480483048]\n",
            "103 groundtruth: [22.152, 17.919, 19.668]\n",
            "103 difference: [0.13595365 9.70153549 9.22084752]\n",
            "SMAPE: 0.15905442965859146\n",
            "\n",
            "\n",
            "104 prediction: [12.891878038644785, 30.371422469615926, 13.721344470977778]\n",
            "104 groundtruth: [28.508, 23.224, 21.83]\n",
            "104 difference: [15.61612196  7.14742247  8.10865553]\n",
            "SMAPE: 0.2364840549131165\n",
            "\n",
            "\n",
            "105 prediction: [14.574753642082213, 45.698087811470025, 25.67185968160629]\n",
            "105 groundtruth: [33.574, 27.286, 22.633]\n",
            "105 difference: [18.99924636 18.41208781  3.03885968]\n",
            "SMAPE: 0.23873195622931306\n",
            "\n",
            "\n",
            "106 prediction: [12.624373286962507, 17.57301807403564, 17.52359569072722]\n",
            "106 groundtruth: [33.537, 27.694, 26.601]\n",
            "106 difference: [20.91262671 10.12098193  9.07740431]\n",
            "SMAPE: 0.29590652202277734\n",
            "\n",
            "\n",
            "107 prediction: [19.548878073692308, 44.256478250026696, 28.951324224472046]\n",
            "107 groundtruth: [37.489, 26.649, 29.495]\n",
            "107 difference: [17.94012193 17.60747825  0.54367578]\n",
            "SMAPE: 0.19363344497245888\n",
            "\n",
            "\n",
            "108 prediction: [14.387893527746195, 20.80069720745085, 11.777134537696824]\n",
            "108 groundtruth: [11.636, 9.6647, 2.5473]\n",
            "108 difference: [ 2.75189353 11.13599721  9.22983454]\n",
            "SMAPE: 0.3264582562745487\n",
            "\n",
            "\n",
            "109 prediction: [15.04482954740523, 27.16171950101852, 24.695581197738637]\n",
            "109 groundtruth: [18.918, 2.1909, 7.7505]\n",
            "109 difference: [ 3.87317045 24.9708195  16.9450812 ]\n",
            "SMAPE: 0.47815726245860524\n",
            "\n",
            "\n",
            "110 prediction: [15.71779578924178, 35.906941294670105, 21.997109949588772]\n",
            "110 groundtruth: [19.31, 18.305, 9.9513]\n",
            "110 difference: [ 3.59220421 17.60194129 12.04580995]\n",
            "SMAPE: 0.2742838822828804\n",
            "\n",
            "\n",
            "111 prediction: [23.678600192069993, 0.758076757192602, 42.44739800691604]\n",
            "111 groundtruth: [18.954, 10.476, 16.613]\n",
            "111 difference: [ 4.72460019  9.71792324 25.83439801]\n",
            "SMAPE: 0.3566631072081066\n",
            "\n",
            "\n",
            "112 prediction: [21.52070939540862, 55.64913690090179, 28.368281722068772]\n",
            "112 groundtruth: [41.637, 17.304, 22.73]\n",
            "112 difference: [20.1162906  38.3451369   5.63828172]\n",
            "SMAPE: 0.3423962811325577\n",
            "\n",
            "\n",
            "113 prediction: [10.250920057296744, 3.7984612584114, 6.935015693306916]\n",
            "113 groundtruth: [24.306, 15.078, 5.7366]\n",
            "113 difference: [14.05507994 11.27953874  1.19841569]\n",
            "SMAPE: 0.401377136042837\n",
            "\n",
            "\n",
            "114 prediction: [8.65535169839859, 11.696422845125197, 15.058951377868638]\n",
            "114 groundtruth: [19.758, 13.773, 5.2297]\n",
            "114 difference: [11.1026483   2.07657715  9.82925138]\n",
            "SMAPE: 0.3102067480639977\n",
            "\n",
            "\n",
            "115 prediction: [8.324852585792527, 7.3959472775459165, 11.895169168710702]\n",
            "115 groundtruth: [39.925, 18.158, 18.518]\n",
            "115 difference: [31.60014741 10.76205272  6.62283083]\n",
            "SMAPE: 0.4700293188615648\n",
            "\n",
            "\n",
            "116 prediction: [11.095563769340508, 5.128527805209144, 22.46116697788237]\n",
            "116 groundtruth: [38.148, 21.958, 16.204]\n",
            "116 difference: [27.05243623 16.82947219  6.25716698]\n",
            "SMAPE: 0.4360099367094499\n",
            "\n",
            "\n",
            "117 prediction: [17.405904382467266, 8.553030788898468, 26.35652035474776]\n",
            "117 groundtruth: [33.68, 24.611, 14.39]\n",
            "117 difference: [16.27409562 16.05796921 11.96652035]\n",
            "SMAPE: 0.3543987307234279\n",
            "\n",
            "\n",
            "118 prediction: [16.53158068656921, 12.284321486949919, 7.242634892463678]\n",
            "118 groundtruth: [23.917, 22.097, 10.506]\n",
            "118 difference: [7.38541931 9.81267851 3.26336511]\n",
            "SMAPE: 0.2210173500520304\n",
            "\n",
            "\n",
            "119 prediction: [10.062587410211556, 1.05829909443855, 16.90649315714835]\n",
            "119 groundtruth: [30.09, 18.005, 18.032]\n",
            "119 difference: [20.02741259 16.94670091  1.12550684]\n",
            "SMAPE: 0.4046505375008043\n",
            "\n",
            "\n",
            "120 prediction: [21.118661016225804, 37.89374202489852, 18.222364783287034]\n",
            "120 groundtruth: [47.905, 20.724, 30.632]\n",
            "120 difference: [26.78633898 17.16974202 12.40963522]\n",
            "SMAPE: 0.31936015758441133\n",
            "\n",
            "\n",
            "121 prediction: [7.7123554050922385, 6.70514702796936, 9.083677679300305]\n",
            "121 groundtruth: [42.404, 22.014, 19.329]\n",
            "121 difference: [34.69164459 15.30885297 10.24532232]\n",
            "SMAPE: 0.5617421183699313\n",
            "\n",
            "\n",
            "122 prediction: [6.8793109059333775, 1.9659939967095839, 6.659703701734537]\n",
            "122 groundtruth: [43.089, 19.373, 22.701]\n",
            "122 difference: [36.20968909 17.407006   16.0412963 ]\n",
            "SMAPE: 0.6919575777978929\n",
            "\n",
            "\n",
            "123 prediction: [9.779871851205822, 15.607744753360734, 27.214572429656982]\n",
            "123 groundtruth: [11.13, 1.3697, 4.4634]\n",
            "123 difference: [ 1.35012815 14.23804475 22.75117243]\n",
            "SMAPE: 0.551127521556769\n",
            "\n",
            "\n",
            "124 prediction: [11.663663685321797, 11.929989606142032, 9.061172604560845]\n",
            "124 groundtruth: [8.0308, 5.5956, 5.0677]\n",
            "124 difference: [3.63286369 6.33438961 3.9934726 ]\n",
            "SMAPE: 0.27187960901642705\n",
            "\n",
            "\n",
            "125 prediction: [24.61215913295746, 43.460642695426934, 23.582359850406643]\n",
            "125 groundtruth: [68.979, 31.19, 37.149]\n",
            "125 difference: [44.36684087 12.2706427  13.56664015]\n",
            "SMAPE: 0.30660415918327943\n",
            "\n",
            "\n",
            "126 prediction: [14.519599378108973, 18.247590959072113, 18.924086987972245]\n",
            "126 groundtruth: [43.788, 36.18, 27.493]\n",
            "126 difference: [29.26840062 17.93240904  8.56891301]\n",
            "SMAPE: 0.350417371414091\n",
            "\n",
            "\n",
            "127 prediction: [6.359108537435526, 10.74243955314159, 10.452310368418692]\n",
            "127 groundtruth: [46.747, 40.562, 31.747]\n",
            "127 difference: [40.38789146 29.81956045 21.29468963]\n",
            "SMAPE: 0.6241199773519714\n",
            "\n",
            "\n",
            "128 prediction: [22.739309370517717, 40.47565251588821, 24.148466885089874]\n",
            "128 groundtruth: [39.313, 38.266, 14.47]\n",
            "128 difference: [16.57369063  2.20965252  9.67846689]\n",
            "SMAPE: 0.15863900971269973\n",
            "\n",
            "\n",
            "SMAPE: 0.39258500160209164\n",
            "Difference less than 5 degree: 0.19010416666666666\n",
            "Difference between 5 and 10 degree: 0.20572916666666666\n",
            "Difference between 10 and 20 degree: 0.2421875\n",
            "Difference above 20 degree: 0.3619791666666667\n",
            "\n",
            "\n",
            "Difference less than 5 degree: 73\n",
            "Difference between 5 and 10 degree: 79\n",
            "Difference between 10 and 20 degree: 93\n",
            "Difference above 20 degree: 139\n",
            "\n",
            "\n",
            "# SMAPE less than 5%: 1\n",
            "# SMAPE between 5% and 10%: 0\n",
            "# SMAPE between 10% and 20%: 8\n",
            "# SMAPE above 20%: 119\n"
          ]
        }
      ],
      "source": [
        "# Compute angles and SMAPE\n",
        "\n",
        "def cobb_angles(img_dir, filenames_csv, all_angles_csv):\n",
        "\n",
        "    # get current model prediction\n",
        "    all_angles = pd.read_csv(all_angles_csv, header= None)\n",
        "    filenames = pd.read_csv(filenames_csv, header= None)\n",
        "    \n",
        "    angles = []\n",
        "    for i, names in enumerate(filenames.iloc[:,0]):\n",
        "\n",
        "        curr_angles = all_angles.loc[i].values\n",
        "\n",
        "        pt_lower_v_index = np.argmax(curr_angles[:8])\n",
        "        pt = np.max(curr_angles[:8])\n",
        "\n",
        "        tl_upper_v_index = np.argmax(curr_angles[8:15]) + 8\n",
        "        tl = np.max(curr_angles[8:15])\n",
        "\n",
        "        mt_index = 15\n",
        "        for i in range(pt_lower_v_index):\n",
        "          mt_index += 14 - i\n",
        "        mt_index += tl_upper_v_index - pt_lower_v_index\n",
        "\n",
        "        mt = curr_angles[mt_index]\n",
        "\n",
        "        angles.append([pt * 180, mt * 180, tl * 180])\n",
        "\n",
        "        \n",
        "    # GT\n",
        "    angle_gT = list(csv.reader(open(\"./drive/MyDrive/boostnet_labeldata/full_test_angles.csv\", 'r')))\n",
        "    for i in range(len(angle_gT)):\n",
        "      for j in range(3):\n",
        "        angle_gT[i][j] = float(angle_gT[i][j])\n",
        "\n",
        "\n",
        "    # print\n",
        "    less_than_five = 0\n",
        "    five_to_ten = 0\n",
        "    ten_to_twenty = 0\n",
        "    twenty_above = 0\n",
        "\n",
        "    smape_below_5_percent = 0\n",
        "    smape_below_10_percent = 0\n",
        "    smape_above_10_percent = 0\n",
        "    smape_above_20_percent = 0\n",
        "    \n",
        "\n",
        "    smape = 0\n",
        "    avg_difference = []\n",
        "    for i in range(128):\n",
        "      print(str(i + 1) + \" prediction: \" + str(angles[i]))\n",
        "      print(str(i + 1) + \" groundtruth: \" + str(angle_gT[i]))\n",
        "      print(str(i + 1) + \" difference: \" + str(np.abs(np.asarray(angle_gT[i]) - np.asarray(angles[i]))))\n",
        "      num = 0\n",
        "      denom = 0\n",
        "      for j in range(3):\n",
        "        diff = np.abs(angle_gT[i][j] - angles[i][j])\n",
        "        num += diff\n",
        "\n",
        "        if diff <= 5:\n",
        "          less_than_five += 1\n",
        "        elif 5 < diff and diff <= 10:\n",
        "          five_to_ten += 1\n",
        "        elif 10 < diff and diff <= 20:\n",
        "          ten_to_twenty += 1\n",
        "        elif 20 < diff:\n",
        "          twenty_above += 1\n",
        "\n",
        "        denom += angle_gT[i][j] + angles[i][j]\n",
        "      smape += (num / denom)\n",
        "      avg_difference.append(np.sum(np.abs(np.asarray(angle_gT[i]) - np.asarray(angles[i]))))\n",
        "\n",
        "      sam = num / denom\n",
        "      if sam >= 0.2:\n",
        "        smape_above_20_percent += 1\n",
        "      elif sam >= 0.1:\n",
        "        smape_above_10_percent += 1\n",
        "      elif sam >= 0.05:\n",
        "        smape_below_10_percent += 1\n",
        "      else:\n",
        "        smape_below_5_percent += 1\n",
        "      print(\"SMAPE: \" + str((num / denom)))\n",
        "      print('\\n')\n",
        "      # plt.plot([i for i in range(len(confidence[i]))], confidence[i])\n",
        "      # plt.show()\n",
        "    smape /= 128\n",
        "\n",
        "    print(\"SMAPE: \" + str(smape))\n",
        "\n",
        "    print(\"Difference less than 5 degree: \" + str(less_than_five / 384))\n",
        "    print(\"Difference between 5 and 10 degree: \" + str(five_to_ten / 384))\n",
        "    print(\"Difference between 10 and 20 degree: \" + str(ten_to_twenty / 384))\n",
        "    print(\"Difference above 20 degree: \" + str(twenty_above / 384))\n",
        "    print(\"\\n\")\n",
        "    print(\"Difference less than 5 degree: \" + str(less_than_five))\n",
        "    print(\"Difference between 5 and 10 degree: \" + str(five_to_ten))\n",
        "    print(\"Difference between 10 and 20 degree: \" + str(ten_to_twenty))\n",
        "    print(\"Difference above 20 degree: \" + str(twenty_above))\n",
        "    print(\"\\n\")\n",
        "    print(\"# SMAPE less than 5%: \" + str(smape_below_5_percent))\n",
        "    print(\"# SMAPE between 5% and 10%: \" + str(smape_below_10_percent))\n",
        "    print(\"# SMAPE between 10% and 20%: \" + str(smape_above_10_percent))\n",
        "    print(\"# SMAPE above 20%: \" + str(smape_above_20_percent))\n",
        "\n",
        "cobb_angles('./drive/MyDrive/boostnet_labeldata/data/test/','./drive/MyDrive/boostnet_labeldata/full_test_filenames.csv','./drive/MyDrive/boostnet_labeldata/model_2/test_all_angles.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CSC2621Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}